{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Torch Hub lib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.utils as vutils\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 压缩后的图片尺寸，设置为64 * 64\n",
    "SX = 64\n",
    "SY = 64\n",
    "N_CHANNELS = 1\n",
    "EXTRINSIC_DIM = 6\n",
    "LATENT_DIM = latent_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集的导入与处理\n",
    "crop images by 128 x 128, downsize to 64 x 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./DATA/\"\n",
    "IMAGE_SUBPATH = \"images\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, \"Dataset_descriptor.csv\"), sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_COLUMNS=['temperature [C]',\n",
    "       'Al-concentration [at.%]', 'O-concentration [at.%]',\n",
    "       'ionization degree [a.u.]', 'average ion energy [eV]', 'pressure [Pa]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对information降维，观察其分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取我们需要用的值\n",
    "y = df[Y_COLUMNS]\n",
    "#做最大最小值归一化\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "# 用tsne对标签进行降维, 默认是降到2维\n",
    "tsne = TSNE(init='pca', learning_rate='auto')\n",
    "y_tsne = tsne.fit_transform(y_scaled)\n",
    "\n",
    "#number of bins per each extrinsic properties\n",
    "BINS=6\n",
    "\n",
    "for Y_column in Y_COLUMNS:\n",
    "    print(Y_column)\n",
    "    fig, axs= plt.subplots(1,2, figsize=(7,3))\n",
    "    im=axs[0].scatter(y_tsne[:,0], y_tsne[:,1], c= df[Y_column])\n",
    "    fig.colorbar(im, ax = axs[0])\n",
    "    h=axs[1].hist(df[Y_column], bins=BINS)\n",
    "    plt.show()\n",
    "\n",
    "binning_labels_dict = {}\n",
    "Y_COLUMNS_BINNING = []\n",
    "for Y_column in Y_COLUMNS:\n",
    "    # histogram means \"直方图\", bins是均匀分组后的边界\n",
    "    cnt, bins = np.histogram(df[Y_column], bins=BINS)\n",
    "    # 为什么要对这个减1？因为后面做searchsorted时，对这个边界的索引可能出问题\n",
    "    bins[0] -= 1\n",
    "    col_name = Y_column + \"_binning\"\n",
    "    # 做这个操作是为了把所有的原始数据分成6组, 用1~6作为标签\n",
    "    binning_labels_dict[col_name] = np.searchsorted(bins, df[Y_column].values)\n",
    "    Y_COLUMNS_BINNING.append(col_name)\n",
    "\n",
    "binning_df = pd.DataFrame(binning_labels_dict)\n",
    "# 给其增加一列“T”，赋值全为1,用来计数，count之后T的值就是这种标签的个数\n",
    "binning_df[\"T\"] = 1\n",
    "# 分别按照Y_COLUMNS_BINNING中的指标分组，统计每组的个数\n",
    "# 这里按照这个列表去groupby,会自动列出所有可能的取值，然后再count，从而计算出每一类的数量，以及所有的类别，这个方法真的是特别巧妙\n",
    "count_bins_df = binning_df.groupby(Y_COLUMNS_BINNING).count()\n",
    "# 每个指标都有\n",
    "# 这里补充一个reset_index的操作，原来的代码没有这个操作导致后面出问题了\n",
    "count_bins_df = count_bins_df.reset_index()\n",
    "count_bins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count=count_bins_df[\"T\"].max()\n",
    "# 与原始数据连接\n",
    "df = pd.concat((df, binning_df), axis=1)\n",
    "df.drop(labels=\"T\", axis=1, inplace=True)\n",
    "count_bins_df = count_bins_df.reset_index()\n",
    "\n",
    "df=pd.merge(df,count_bins_df,on=Y_COLUMNS_BINNING)\n",
    "\n",
    "df[\"weight\"] = max_count/df[\"T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 至此，csv数据处理完成\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image cropping & resizing \n",
    "BOX_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "CROP_PER_IMAGE = 128\n",
    "\n",
    "# ceil是向上取整\n",
    "batch_count = int(np.ceil(len(df)/BATCH_SIZE))\n",
    "\n",
    "YS = []\n",
    "WEIGHTS = []\n",
    "XS = []\n",
    "\n",
    "for b in range(0, batch_count):\n",
    "    print(b*BATCH_SIZE, \"->\", min(len(df), b*BATCH_SIZE+BATCH_SIZE)-1)\n",
    "    batch_indices = np.arange(b*BATCH_SIZE,min(len(df),b*BATCH_SIZE+BATCH_SIZE))\n",
    "\n",
    "    for ind in batch_indices:\n",
    "        fname = df.loc[ind, \"file name\"]\n",
    "        fname = os.path.join(DATA_PATH, IMAGE_SUBPATH, fname)\n",
    "        im = Image.open(fname)\n",
    "        for rep in range(CROP_PER_IMAGE):\n",
    "            # 剪裁\n",
    "            left = np.random.randint(0, im.width - BOX_SIZE)\n",
    "            upper = np.random.randint(0, im.height - BOX_SIZE)\n",
    "\n",
    "            box = left, upper, left+BOX_SIZE, upper+BOX_SIZE\n",
    "\n",
    "            sub_image = im.crop(box)\n",
    "\n",
    "            sub_image = sub_image.resize((SX, SY), resample=Image.Resampling.LANCZOS)\n",
    "\n",
    "            sub_image_np = np.array(sub_image)\n",
    "            sub_image_np = ((sub_image_np-127.5)/127.5).reshape(SX, SY, 1)\n",
    "            # YS存储该图片对应的information\n",
    "            YS.append(df.loc[ind, Y_COLUMNS].values)\n",
    "            # WEIGHTS，存储这个图片的权重\n",
    "            WEIGHTS.append(df.loc[ind, \"weight\"])\n",
    "            # XS存储图片本身\n",
    "            XS.append(sub_image_np)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YS = np.array(YS)\n",
    "XS = np.array(XS)\n",
    "WEIGHTS = np.array(WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对标签信息做归一化\n",
    "YS_scaled = scaler.fit_transform(YS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(XS[2,:,:,0])\n",
    "YS_scaled[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XS = XS.reshape(-1, 1, 64, 64)\n",
    "XS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义神经网络，准备机器学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = DATA_PATH\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "label_dim = 6\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetData(Dataset):\n",
    "    def __init__(self, datax, labely) -> None:\n",
    "        self.data = torch.from_numpy(datax.astype(float))\n",
    "        self.label = torch.from_numpy(labely.astype(float))\n",
    "        self.len = len(datax)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "dataset = GetData(XS, YS_scaled)\n",
    "\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available and ngpu > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "print(real_batch[0].size())\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(real_batch[0].numpy()[0, 0, :, :])\n",
    "print(real_batch[1][0])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(real_batch[0].numpy()[1, 0, :, :])\n",
    "# plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显示正常，说明我们的数据集读取无误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    r\"\"\" It is mainly based on the mobile net network as the backbone network generator.\n",
    "    Args:\n",
    "        image_size (int): The size of the image. (Default: 28)\n",
    "        channels (int): The channels of the image. (Default: 1)\n",
    "        num_classes (int): Number of classes for dataset. (Default: 10)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_size: int = 64, channels: int = 1, num_classes: int = label_dim) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.channels = channels\n",
    "        self.num_classes = num_classes\n",
    "        # self.label_embedding = nn.Linear(num_classes, num_classes)\n",
    "        # self.label_embedding = nn.Embedding(num_classes, num_classes)\n",
    "        self.ylabel = nn.Sequential(\n",
    "            nn.Linear(num_classes, nz),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            # 1*1*200 ->4*4*512 \n",
    "            nn.ConvTranspose2d(nz + nz, 64*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(64*8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 4*4*512 -> 8*8*256\n",
    "            nn.ConvTranspose2d(64*8, 64*4, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(64*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 8*8*256 -> 16*16*128\n",
    "            nn.ConvTranspose2d(64*4, 64*2, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(64*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 16*16*128 -> 32*32*64\n",
    "            nn.ConvTranspose2d(64*2, 64, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # 32*32*64 -> 64*64*1\n",
    "            nn.ConvTranspose2d( 64, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # 这一步似乎可以省略\n",
    "        y=y.reshape(-1,self.num_classes)\n",
    "        y = self.ylabel(y)\n",
    "        y=y.reshape(-1,nz,1,1)\n",
    "        x=x.reshape(-1,nz,1,1)\n",
    "        out = torch.cat([x, y] , dim=1)\n",
    "        out=out.view(-1,100+nz,1,1)\n",
    "\n",
    "        out = self.main(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.ylabel=nn.Sequential(\n",
    "            nn.Linear(label_dim, 64*64*1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            #input size nc +  1 che è la condizione\n",
    "            nn.Conv2d(nc+1, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64*2 , 64*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64*4 , 64*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64*8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        y = y.reshape(batch_size,label_dim)\n",
    "        y = self.ylabel(y)\n",
    "        y=y.view(-1, 1, image_size,image_size)\n",
    "        out = torch.cat([x, y] , dim=1)\n",
    "        out = self.main(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the DCGAN paper, the authors specify that all model weights shall be randomly initialized from a Normal distribution with mean=0, stdev=0.02. The weights_init function takes an initialized model as input and reinitializes all convolutional, convolutional-transpose, and batch normalization layers to meet this criteria. This function is applied to the models immediately after initialization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=EXTRINSIC_DIM):\n",
    "    # generate points in the latent space\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    # generate labels\n",
    "    labels = np.random.choice(len(YS),size=n_samples)\n",
    "    weights = WEIGHTS[labels]\n",
    "    labels=YS_scaled[labels]    \n",
    "    return torch.from_numpy(z_input), torch.from_numpy(labels), weights\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input, weights_input = generate_latent_points(nz, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator(z_input.float(), labels_input.float())\n",
    "    # create class labels\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return images, labels_input, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN(G, D, G_opt, D_opt, dataset):\n",
    "    for i,(data,label) in tqdm(enumerate(dataset)):\n",
    "\n",
    "        '''\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Training Images\")\n",
    "        plt.imshow(np.transpose(vutils.make_grid(data, padding=2).cpu(),(1,2,0)))\n",
    "        plt.show()\n",
    "        '''\n",
    "    \n",
    "        ## Train with all-real batch        \n",
    "        D_opt.zero_grad()\n",
    "\n",
    "        # 真实数据 \n",
    "        x_real = data.to(device)\n",
    "        y_real = torch.ones(batch_size, ).to(device)\n",
    "        # label_onehot = onehot[label]\n",
    "        y_real_predict = D(x_real.float(), label.float()).squeeze()      \n",
    "        d_real_loss = criterion(y_real_predict, y_real)\n",
    "        d_real_loss.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "\n",
    "        # noise = torch.randn(batch_size, nz, 1, 1, device = device)\n",
    "        # noise_label = (torch.rand(batch_size, 1) * label_dim).type(torch.LongTensor).squeeze()\n",
    "        #print(noise_label)\n",
    "        # noise_label_onehot = onehot[noise_label].to(device)  # Genera label in modo casuale (-1,)\n",
    "        # x_fake = G(noise, noise_label_onehot)       #Genera immagini false\n",
    "        # y_fake = torch.zeros(batch_size, ).to(device)    # Assegna label 0\n",
    "        # y_fake_predict = D(x_fake, noise_label_onehot).squeeze()\n",
    "\n",
    "        # 生成fake数据\n",
    "        x_fake, noise_label, y_fake= generate_fake_samples(G, label_dim, batch_size)\n",
    "        y_fake_predict = D(x_fake.float(), noise_label.float()).squeeze()\n",
    "        y_fake = torch.from_numpy(y_fake).reshape(-1).float()\n",
    "        d_fake_loss = criterion(y_fake_predict, y_fake)\n",
    "        d_fake_loss.backward()\n",
    "        D_opt.step()\n",
    "         \n",
    "        # (2) Update G network: maximize log(D(G(z)))         \n",
    "        G_opt.zero_grad()\n",
    "         \n",
    "        #noise = torch.randn(batch_size, z_dim, 1, 1, device = device)\n",
    "        #noise_label = (torch.rand(batch_size, 1) * label_dim).type(torch.LongTensor).squeeze()\n",
    "        #noise_label_onehot = onehot[noise_label].to(device)   # Genera label in modo casuale (-1,)\n",
    "        # x_fake = G(noise, noise_label_onehot)\n",
    "        x_fake, noise_label, y_fake= generate_fake_samples(G, label_dim, batch_size)\n",
    "        y_fake = torch.ones(batch_size, ).to(device)    # Il y_fake qui è lo stesso di y_real sopra, entrambi sono 1\n",
    "        y_fake_predict = D(x_fake.float(), noise_label.float()).squeeze()\n",
    "        g_loss = criterion(y_fake_predict, y_real)    # Usa direttamente y_real per essere più intuitivo\n",
    "        g_loss.backward()\n",
    "        G_opt.step()\n",
    "\n",
    "        err_D = d_fake_loss.item() + d_real_loss.item()\n",
    "        err_G = g_loss.item()\n",
    "        '''\n",
    "        if i%50 == 0:\n",
    "            with torch.no_grad():\n",
    "                out_imgs = G(fixed_noise.to(device), fixed_label.to(device))\n",
    "            save_image(out_imgs,f\"{PATH}{i}.png\", nrow = 10) #aggiungi percorso: \"path/iterazione_classe.png\" es \"pippo/20000_3.png\"\n",
    "        '''\n",
    "    return err_D, err_G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "D = Discriminator()\n",
    "D.apply(weights_init)\n",
    "\n",
    "G = Generator()\n",
    "G.apply(weights_init)\n",
    "\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr= lr, betas=(beta1, 0.999))#, betas=(beta1, 0.999))\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr= lr, betas=(beta1, 0.999))#, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(100,100)\n",
    "fixed_noise = fixed_noise.reshape(100,100,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = []\n",
    "G_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    if epoch == 5 or epoch == 10:\n",
    "        G_opt.param_groups[0]['lr'] /= 2\n",
    "        D_opt.param_groups[0]['lr'] /= 2\n",
    "        \n",
    "    # training\n",
    "    err_D, err_G = train_GAN(G, D, G_opt, D_opt, dataloader)\n",
    "\n",
    "    D_loss.append(err_D)\n",
    "    G_loss.append(err_G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71342f419acc3ba6ae382518c4ba2a9e6f9bd8751a76a463bc8e77674675b221"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
